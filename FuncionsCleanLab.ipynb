{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f133cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " def generate_noisy_labels(y, noise_matrix, verbose=False):\n",
    "    \"\"\"Generates noisy labels s (shape (N, 1)) from perfect labels y,\n",
    "    'exactly' yielding the provided noise_matrix between s and y.\n",
    "    Below we provide a for loop implementation of what this function does.\n",
    "    We do not use this implementation as it is not a fast algorithm, but\n",
    "    it explains as Python pseudocode what is happening in this function.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array (shape (N, 1))\n",
    "        Perfect labels, without any noise. Contains K distinct natural number\n",
    "        classes, e.g. 0, 1,..., K-1\n",
    "    noise_matrix : np.array of shape (K, K), K = number of classes\n",
    "        A conditional probablity matrix of the form P(s=k_s|y=k_y) containing\n",
    "        the fraction of examples in every class, labeled as every other class.\n",
    "        Assumes columns of noise_matrix sum to 1.\n",
    "    Examples\n",
    "    --------\n",
    "    .. code:: python\n",
    "        # Generate s\n",
    "        count_joint = (noise_matrix * py * len(y)).round().astype(int)\n",
    "        s = np.array(y)\n",
    "        for k_s in range(K):\n",
    "            for k_y in range(K):\n",
    "                if k_s != k_y:\n",
    "                    idx_flip = np.where((s==k_y)&(y==k_y))[0]\n",
    "                    if len(idx_flip): # pragma: no cover\n",
    "                        s[np.random.choice(\n",
    "                            idx_flip,\n",
    "                            count_joint[k_s][k_y],\n",
    "                            replace=False,\n",
    "                        )] = k_s\n",
    "    \"\"\"\n",
    "\n",
    "    # Make y a numpy array, if it is not\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # Number of classes\n",
    "    K = len(noise_matrix)\n",
    "\n",
    "    # Compute p(y=k)\n",
    "    py = value_counts(y) / float(len(y))\n",
    "\n",
    "    # Counts of pairs (s, y)\n",
    "    count_joint = (noise_matrix * py * len(y)).astype(int)\n",
    "    # Remove diagonal entries as they do not involve flipping of labels.\n",
    "    np.fill_diagonal(count_joint, 0)\n",
    "    \n",
    "    print(\"------------------------------------------\")\n",
    "    # Generate s\n",
    "    s = np.array(y)\n",
    "    for k in range(K):  # Iterate over true class y == k\n",
    "        print(\"k = \", k)\n",
    "        # Get the noisy s labels that have non-zero counts\n",
    "        s_labels = np.where(count_joint[:, k] != 0)[0]\n",
    "        print(\"noisy labels that have non-zero counts = \", s_labels)\n",
    "        # Find out how many of each noisy s label we need to flip to\n",
    "        s_counts = count_joint[s_labels, k]\n",
    "        print(\"how many of each noisy label we need to flip = \", s_counts)\n",
    "        # Create a list of the new noisy labels\n",
    "        noise = [s_labels[i] for i, c in enumerate(s_counts) for z in range(c)]\n",
    "        print(\"list of new noisy labels = \", noise)\n",
    "        # Randomly choose y labels for class k and set them to the noisy labels.\n",
    "        idx_flip = np.where((s == k) & (y == k))[0]\n",
    "        print(\"Randomly choose y labels for class k and set them to the noisy labels = \",idx_flip)\n",
    "        if len(idx_flip) and len(noise) and len(idx_flip) >= len(\n",
    "               noise):  # pragma: no cover\n",
    "            s[np.random.choice(idx_flip, len(noise), replace=False)] = noise\n",
    "        print(\"noisy labels = \",s)\n",
    "        print(\"------------------------------------------\")\n",
    "\n",
    "    # Validate that s indeed produces the correct noise_matrix (or close to it)\n",
    "    # Compute the actual noise matrix induced by s\n",
    "    # counts = confusion_matrix(s, y).astype(float)\n",
    "    # new_noise_matrix = counts / counts.sum(axis=0)\n",
    "    # assert(np.linalg.norm(noise_matrix - new_noise_matrix) <= 2)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5f55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f1a5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_matrix = np.array([[.7,.2,.04,.03,.03],\n",
    "                         [.2,.7,.04,.03,.03],\n",
    "                         [.05,.01,.68,.13,.13],\n",
    "                         [.01,.02,.12,.7,.15],\n",
    "                         [.04,.04,.17,.05,.7]])\n",
    "\n",
    "np.sum(noise_matrix,1) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ab0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2, 0, 3, 1, 4, 1, 4, 1, 1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5b2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import, division, \\\n",
    "    unicode_literals, with_statement\n",
    "import numpy as np\n",
    "from cleanlab.util import value_counts, confusion_matrix\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011b7fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "k =  0\n",
      "noisy labels that have non-zero counts =  []\n",
      "how many of each noisy label we need to flip =  []\n",
      "list of new noisy labels =  []\n",
      "Randomly choose y labels for class k and set them to the noisy labels =  [1]\n",
      "noisy labels =  [2 0 3 1 4 1 4 1 1 4]\n",
      "------------------------------------------\n",
      "k =  1\n",
      "noisy labels that have non-zero counts =  []\n",
      "how many of each noisy label we need to flip =  []\n",
      "list of new noisy labels =  []\n",
      "Randomly choose y labels for class k and set them to the noisy labels =  [3 5 7 8]\n",
      "noisy labels =  [2 0 3 1 4 1 4 1 1 4]\n",
      "------------------------------------------\n",
      "k =  2\n",
      "noisy labels that have non-zero counts =  []\n",
      "how many of each noisy label we need to flip =  []\n",
      "list of new noisy labels =  []\n",
      "Randomly choose y labels for class k and set them to the noisy labels =  [0]\n",
      "noisy labels =  [2 0 3 1 4 1 4 1 1 4]\n",
      "------------------------------------------\n",
      "k =  3\n",
      "noisy labels that have non-zero counts =  []\n",
      "how many of each noisy label we need to flip =  []\n",
      "list of new noisy labels =  []\n",
      "Randomly choose y labels for class k and set them to the noisy labels =  [2]\n",
      "noisy labels =  [2 0 3 1 4 1 4 1 1 4]\n",
      "------------------------------------------\n",
      "k =  4\n",
      "noisy labels that have non-zero counts =  []\n",
      "how many of each noisy label we need to flip =  []\n",
      "list of new noisy labels =  []\n",
      "Randomly choose y labels for class k and set them to the noisy labels =  [4 6 9]\n",
      "noisy labels =  [2 0 3 1 4 1 4 1 1 4]\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 1, 4, 1, 4, 1, 1, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_noisy_labels(y, noise_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a049fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array([2, 0, 3, 1, 4, 1, 4, 1, 1, 4])\n",
    "psx = np.array([[6.54160162e-04, 3.03065872e-06, 9.27881896e-01, 3.08100454e-04,\n",
    "         7.11528882e-02],\n",
    "        [9.52379167e-01, 2.47183759e-02, 1.75267160e-02, 5.93801611e-04,\n",
    "         4.78204014e-03],\n",
    "        [2.07699835e-09, 4.27654939e-10, 5.88927560e-06, 9.99994159e-01,\n",
    "         4.86104665e-17],\n",
    "        [8.21316838e-01, 1.68881238e-01, 7.79483374e-03, 2.00584810e-03,\n",
    "         1.22517827e-06],\n",
    "        [2.54394426e-08, 3.22418398e-10, 1.06855035e-01, 4.39613643e-08,\n",
    "         8.93144906e-01],\n",
    "        [4.56457287e-01, 5.43138981e-01, 2.59662047e-04, 1.44051432e-04,\n",
    "         6.48661169e-09],\n",
    "        [2.46501830e-03, 1.09589223e-06, 2.93296985e-02, 1.29379432e-05,\n",
    "         9.68191206e-01],\n",
    "        [1.82137087e-01, 8.17485034e-01, 3.06710252e-04, 7.09961532e-05,\n",
    "         2.27663620e-07],\n",
    "        [5.11904418e-01, 4.87983733e-01, 8.93332399e-05, 2.25182412e-05,\n",
    "         1.91881022e-09],\n",
    "        [4.90616987e-13, 2.53091194e-11, 2.81081963e-02, 7.72716169e-10,\n",
    "         9.71891820e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93399107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 3, 1, 4, 1, 4, 1, 1, 4]), (10, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s,psx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc42bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise_indices(\n",
    "        s,\n",
    "        psx,\n",
    "        frac_noise=1.0,\n",
    "        prune_method='prune_by_noise_rate',\n",
    "        verbose=0,\n",
    "):\n",
    "    \"\"\"Returns the indices of most likely (confident) label errors in s. The\n",
    "    number of indices returned is specified by frac_of_noise. When\n",
    "    frac_of_noise = 1.0, all \"confident\" estimated noise indices are returned.\n",
    "    * If you encounter the error 'psx is not defined', try setting n_jobs = 1.\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : np.array\n",
    "      A binary vector of labels, s, which may contain mislabeling. \"s\" denotes\n",
    "      the noisy label instead of \\\\tilde(y), for ASCII encoding reasons.\n",
    "    psx : np.array (shape (N, K))\n",
    "      P(s=k|x) is a matrix with K (noisy) probabilities for each of the N\n",
    "      examples x.\n",
    "      This is the probability distribution over all K classes, for each\n",
    "      example, regarding whether the example has label s==k P(s=k|x).\n",
    "      psx should have been computed using 3+ fold cross-validation.\n",
    "    prune_method : str (default: 'prune_by_noise_rate')\n",
    "      Possible Values: 'prune_by_class', 'prune_by_noise_rate', or 'both'.\n",
    "      Method used for pruning.\n",
    "      1. 'prune_by_noise_rate': works by removing examples with\n",
    "      *high probability* of being mislabeled for every non-diagonal\n",
    "      in the prune_counts_matrix (see pruning.py).\n",
    "      2. 'prune_by_class': works by removing the examples with *smallest\n",
    "      probability* of belonging to their given class label for every class.\n",
    "      3. 'both': Finds the examples satisfying (1) AND (2) and\n",
    "      removes their set conjunction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of classes s\n",
    "    K = len(psx.T)\n",
    "    # Boolean set to true if dataset is large\n",
    "    big_dataset = K * len(s) > 1e8\n",
    "    # Ensure labels are of type np.array()\n",
    "    s = np.asarray(s)\n",
    "\n",
    "    if confident_joint is None:\n",
    "        from cleanlab.latent_estimation import compute_confident_joint\n",
    "        confident_joint = compute_confident_joint(\n",
    "            s=s,\n",
    "            psx=psx,\n",
    "            multi_label=multi_label,\n",
    "        )\n",
    "\n",
    "    # Leave at least MIN_NUM_PER_CLASS examples per class.\n",
    "    # NOTE prune_count_matrix is transposed (relative to confident_joint)\n",
    "    prune_count_matrix = keep_at_least_n_per_class(\n",
    "        prune_count_matrix=confident_joint.T,\n",
    "        n=MIN_NUM_PER_CLASS,\n",
    "        frac_noise=frac_noise,\n",
    "    )\n",
    "\n",
    "    if num_to_remove_per_class is not None:\n",
    "        # Estimate joint probability distribution over label errors\n",
    "        psy = prune_count_matrix / np.sum(prune_count_matrix, axis=1)\n",
    "        noise_per_s = psy.sum(axis=1) - psy.diagonal()\n",
    "        # Calibrate s.t. noise rates sum to num_to_remove_per_class\n",
    "        tmp = (psy.T * num_to_remove_per_class / noise_per_s).T\n",
    "        np.fill_diagonal(tmp, s_counts - num_to_remove_per_class)\n",
    "        prune_count_matrix = round_preserving_row_totals(tmp)\n",
    "\n",
    "    if n_jobs > 1:  # Prepare multiprocessing shared data\n",
    "        if multi_label:\n",
    "            _s = RawArray('I', int2onehot(s).flatten())\n",
    "        else:\n",
    "            _s = RawArray('I', s)\n",
    "        _s_counts = RawArray('I', s_counts)\n",
    "        _prune_count_matrix = RawArray(\n",
    "            'I', prune_count_matrix.flatten())\n",
    "        _psx = RawArray(\n",
    "            'f', psx.flatten())\n",
    "    else:  # Multiprocessing is turned off. Create tuple with all parameters\n",
    "        args = (s, s_counts, prune_count_matrix, psx, multi_label)\n",
    "\n",
    "    # Perform Pruning with threshold probabilities from BFPRT algorithm in O(n)\n",
    "    # Operations are parallelized across all CPU processes\n",
    "    if prune_method == 'prune_by_class' or prune_method == 'both':\n",
    "        if n_jobs > 1:  # parallelize\n",
    "            with multiprocessing_context(\n",
    "                    n_jobs,\n",
    "                    initializer=_init,\n",
    "                    initargs=(_s, _s_counts, _prune_count_matrix,\n",
    "                              prune_count_matrix.shape, _psx, psx.shape,\n",
    "                              multi_label),\n",
    "            ) as p:\n",
    "                if verbose:\n",
    "                    print('Parallel processing label errors by class.')\n",
    "                sys.stdout.flush()\n",
    "                if big_dataset and tqdm_exists:\n",
    "                    noise_masks_per_class = list(\n",
    "                        tqdm.tqdm(p.imap(_prune_by_class, range(K)), total=K),\n",
    "                    )\n",
    "                else:\n",
    "                    noise_masks_per_class = p.map(_prune_by_class, range(K))\n",
    "        else:  # n_jobs = 1, so no parallelization\n",
    "            noise_masks_per_class = [_prune_by_class(k, args) for k in range(K)]\n",
    "        label_errors_mask = np.stack(noise_masks_per_class).any(axis=0)\n",
    "\n",
    "    if prune_method == 'both':\n",
    "        label_errors_mask_by_class = label_errors_mask\n",
    "\n",
    "    if prune_method == 'prune_by_noise_rate' or prune_method == 'both':\n",
    "        if n_jobs > 1:  # parallelize\n",
    "            with multiprocessing_context(\n",
    "                    n_jobs,\n",
    "                    initializer=_init,\n",
    "                    initargs=(_s, _s_counts, _prune_count_matrix,\n",
    "                              prune_count_matrix.shape, _psx, psx.shape,\n",
    "                              multi_label),\n",
    "            ) as p:\n",
    "                if verbose:\n",
    "                    print('Parallel processing label errors by noise rate.')\n",
    "                sys.stdout.flush()\n",
    "                if big_dataset and tqdm_exists:\n",
    "                    noise_masks_per_class = list(\n",
    "                        tqdm.tqdm(p.imap(_prune_by_count, range(K)), total=K)\n",
    "                    )\n",
    "                else:\n",
    "                    noise_masks_per_class = p.map(_prune_by_count, range(K))\n",
    "        else:  # n_jobs = 1, so no parallelization\n",
    "            noise_masks_per_class = [_prune_by_count(k, args) for k in range(K)]\n",
    "        label_errors_mask = np.stack(noise_masks_per_class).any(axis=0)\n",
    "\n",
    "    if prune_method == 'both':\n",
    "        label_errors_mask = label_errors_mask & label_errors_mask_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12de415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "from cleanlab.noise_generation import generate_noisy_labels\n",
    "from cleanlab.util import print_noise_matrix\n",
    "from cleanlab import baseline_methods\n",
    "from cleanlab.latent_estimation import compute_confident_joint\n",
    "from cleanlab import baseline_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a481971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_argmax(psx, s):\n",
    "    '''This is the simplest baseline approach. Just consider \n",
    "    anywhere argmax != s as a label error.\n",
    "    Parameters\n",
    "    ----------\n",
    "    s : np.array\n",
    "        A discrete vector of noisy labels, i.e. some labels may be erroneous.\n",
    "    psx : np.array (shape (N, K))\n",
    "        P(label=k|x) is a matrix with K (noisy) probabilities for each of the\n",
    "        N examples x. This is the probability distribution over all K classes,\n",
    "        for each example, regarding whether the example has label s==k P(s=k|x).\n",
    "        psx should have been computed using 3 (or higher) fold cross-validation.\n",
    "    Returns\n",
    "    -------\n",
    "        A boolean mask that is true if the example belong\n",
    "        to that index is label error..'''\n",
    "    \n",
    "    return np.argmax(psx, axis=1) != np.asarray(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1352c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_error_mask = np.zeros(len(s), dtype=bool)\n",
    "label_error_indices = compute_confident_joint(\n",
    "    s, psx, return_indices_of_off_diagonals=True)[1]\n",
    "baseline_conf_joint_only = label_error_mask    \n",
    "\n",
    "# Method: C_confusion\n",
    "baseline_argmax = baseline_methods.baseline_argmax(psx, s)\n",
    "\n",
    "# Method: CL: PBC\n",
    "baseline_cl_pbc = cleanlab.pruning.get_noise_indices(\n",
    "    s, psx, prune_method='prune_by_class')\n",
    "\n",
    "# Method: CL: PBNR\n",
    "baseline_cl_pbnr = cleanlab.pruning.get_noise_indices(\n",
    "            s, psx, prune_method='prune_by_noise_rate')\n",
    "\n",
    "# Method: CL: C+NR\n",
    "baseline_cl_both = cleanlab.pruning.get_noise_indices(\n",
    "    s, psx, prune_method='both')\n",
    "\n",
    "clean_labels = {\n",
    "        'conf_joint_only': ~baseline_conf_joint_only,\n",
    "        'pruned_argmax': ~baseline_argmax,\n",
    "        'cl_pbc': ~baseline_cl_pbc,\n",
    "        'cl_pbnr': ~baseline_cl_pbnr,\n",
    "        'cl_both': ~baseline_cl_both,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
