{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f523d167",
   "metadata": {
    "id": "comfortable-avenue"
   },
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1231d0",
   "metadata": {
    "id": "blond-ceramic",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7455e0d",
   "metadata": {
    "id": "transsexual-decision"
   },
   "source": [
    "## Lectura de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a7c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2afbd7f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28264,
     "status": "ok",
     "timestamp": 1638284310466,
     "user": {
      "displayName": "Aida Fernandez",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06772576507680919815"
     },
     "user_tz": -60
    },
    "id": "tC7AESnKeKC6",
    "outputId": "0d284775-c8bd-44a2-b2a8-c901f140af35",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aidaf\\\\TFG'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610d135e",
   "metadata": {
    "id": "ukoFgnSEkhUd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aidaf\\\\TFG\\\\lung_colon_image_set'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd() + \"\\\\lung_colon_image_set\")\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883368bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n"
     ]
    }
   ],
   "source": [
    "classes = os. listdir(data_dir)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43dacf52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dades_Y = np.load('labels.npy')\n",
    "dades_X = np.load('images.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddeb48",
   "metadata": {
    "id": "bright-brisbane"
   },
   "source": [
    "## Descripció de les dades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291ae07",
   "metadata": {
    "id": "excess-dictionary"
   },
   "source": [
    "Dimensió: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8bedda0",
   "metadata": {
    "id": "relative-apartment",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de les dades :  (25000, 100, 100, 3) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensions de les dades : ', dades_X.shape, dades_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857531c",
   "metadata": {
    "id": "diagnostic-individual"
   },
   "source": [
    "Nombre de classes i etiquetes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c908c60b",
   "metadata": {
    "id": "close-frontier"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de classes :  5\n",
      "Etiquetes de les classes :  ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n"
     ]
    }
   ],
   "source": [
    "n_classes = len(classes)\n",
    "print('Nombre de classes : ', n_classes)\n",
    "print('Etiquetes de les classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a58a67",
   "metadata": {
    "id": "unsigned-marathon"
   },
   "source": [
    "Distribució de les classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0e9471a",
   "metadata": {
    "id": "fossil-lancaster",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribució de les classes :  Counter({3: 5000, 1: 5000, 4: 5000, 2: 5000, 0: 5000})\n"
     ]
    }
   ],
   "source": [
    "ocurrences=collections.Counter(dades_Y)\n",
    "\n",
    "print(\"Distribució de les classes : \",ocurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056650e0",
   "metadata": {
    "id": "manufactured-begin"
   },
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0801dc",
   "metadata": {
    "id": "equal-cloud"
   },
   "source": [
    "One-hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444a37b0",
   "metadata": {
    "id": "herbal-concentrate",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dades_Y_one_hot = np.array(pd.get_dummies(dades_Y))\n",
    "dades_Y_one_hot = dades_Y_one_hot.astype('float32')\n",
    "dades_Y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb22dafe",
   "metadata": {
    "id": "orange-ceremony"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 100, 100, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dades_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fea84f",
   "metadata": {
    "id": "aerial-corruption"
   },
   "source": [
    "Split validation-train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d8f6b00",
   "metadata": {
    "id": "portable-cholesterol"
   },
   "outputs": [],
   "source": [
    "train_X_aux,valid_X,train_label,valid_label = train_test_split(dades_X, dades_Y_one_hot, test_size=0.1, \n",
    "                                                           random_state=13,stratify=dades_Y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd0557a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22500, 100, 100, 3), (2500, 100, 100, 3), (22500, 5), (2500, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_aux.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a178d4",
   "metadata": {
    "id": "attached-wheel"
   },
   "source": [
    "Mostrem que efectivament la mostra de validació està estratificada per classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15e3f97d",
   "metadata": {
    "id": "coral-framework",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribució de les classes :  Counter({0: 500, 4: 500, 2: 500, 1: 500, 3: 500})\n"
     ]
    }
   ],
   "source": [
    "ocurrences2=collections.Counter(np.argmax(np.round(valid_label),axis=1))\n",
    "\n",
    "print(\"Distribució de les classes : \",ocurrences2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9db4e",
   "metadata": {},
   "source": [
    "## Methods to Standardize Research with Noisy Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f66e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalization.\n",
    "\n",
    "# Set the sparsity of the noise matrix.\n",
    "FRAC_ZERO_NOISE_RATES = 0.0 # Consider increasing to 0.5\n",
    "# A proxy for the fraction of labels that are correct.\n",
    "avg_trace = 0.65 # ~35% wrong labels. Increasing makes the problem easier.\n",
    "# Amount of data for each dataset.\n",
    "dataset_size = 400 # Try 250 or 400 to use less or more data.\n",
    "# Step size in the mesh.\n",
    "h = .02  \n",
    "\n",
    "py = np.bincount(dades_Y) / float(len(dades_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8621c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cleanlab.noise_generation import generate_noise_matrix_from_trace\n",
    "from cleanlab.noise_generation import generate_noisy_labels\n",
    "from cleanlab.util import print_noise_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e26883e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a noise matrix (guarantees learnability)\n",
    "noise_matrix = generate_noise_matrix_from_trace(\n",
    "    K = n_classes, \n",
    "    trace = n_classes * avg_trace,\n",
    "    py = py,\n",
    "    frac_zero_noise_rates = FRAC_ZERO_NOISE_RATES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d923a11b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Noise Matrix (aka Noisy Channel) P(s|y) of shape (5, 5)\n",
      " p(s|y)\ty=0\ty=1\ty=2\ty=3\ty=4\n",
      "\t---\t---\t---\t---\t---\n",
      "s=0 |\t0.6\t0.02\t0.1\t0.13\t0.03\n",
      "s=1 |\t0.12\t0.95\t0.09\t0.08\t0.05\n",
      "s=2 |\t0.03\t0.01\t0.7\t0.02\t0.35\n",
      "s=3 |\t0.06\t0.02\t0.0\t0.59\t0.16\n",
      "s=4 |\t0.19\t0.01\t0.12\t0.19\t0.42\n",
      "\tTrace(matrix) = 3.25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_noise_matrix(noise_matrix)\n",
    "np.random.seed(seed=1)\n",
    "# Create the noisy labels. This method is exact w.r.t. the noise_matrix.\n",
    "y_train_w_errors = generate_noisy_labels(dades_Y, noise_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c91b1e28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dades_Y_one_hot_noisy = np.array(pd.get_dummies(y_train_w_errors))\n",
    "dades_Y_one_hot_noisy = dades_Y_one_hot_noisy.astype('float32')\n",
    "dades_Y_one_hot_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0930cf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22500, 100, 100, 3), (2500, 100, 100, 3), (22500, 5), (2500, 5))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X,valid_X,train_label_noisy,valid_label_noisy = train_test_split(dades_X, dades_Y_one_hot_noisy, \n",
    "                                                                           test_size=0.1, random_state=13,\n",
    "                                                                           stratify=dades_Y_one_hot_noisy)\n",
    "train_X.shape,valid_X.shape,train_label.shape,valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40e7679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Rescaling(1./255, input_shape=(dades_X.shape[1],dades_X.shape[2],3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear', padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbb9d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a59a7523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "88/88 [==============================] - 383s 4s/step - loss: 1.5504 - accuracy: 0.4504 - val_loss: 2.0117 - val_accuracy: 0.2032\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 319s 4s/step - loss: 1.2323 - accuracy: 0.5378 - val_loss: 2.2215 - val_accuracy: 0.2032\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 310s 4s/step - loss: 1.1778 - accuracy: 0.5655 - val_loss: 2.1380 - val_accuracy: 0.2012\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 306s 3s/step - loss: 1.1222 - accuracy: 0.5859 - val_loss: 2.2328 - val_accuracy: 0.2020\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 305s 3s/step - loss: 1.0763 - accuracy: 0.6035 - val_loss: 2.4135 - val_accuracy: 0.2016\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 303s 3s/step - loss: 1.0321 - accuracy: 0.6162 - val_loss: 2.0442 - val_accuracy: 0.1964\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 304s 3s/step - loss: 0.9932 - accuracy: 0.6247 - val_loss: 2.5249 - val_accuracy: 0.1940\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 348s 4s/step - loss: 0.9357 - accuracy: 0.6453 - val_loss: 2.4682 - val_accuracy: 0.1948\n",
      "Epoch 9/20\n",
      "15/88 [====>.........................] - ETA: 4:15 - loss: 0.8733 - accuracy: 0.6685"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3804/1974971229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# train the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m H = model.fit(train_X, train_label_noisy, batch_size=BS, epochs=EPOCHS,\n\u001b[0m\u001b[0;32m      8\u001b[0m               verbose=1, validation_data=(valid_X, valid_label))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 _r=1):\n\u001b[0;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model on the augmented dataset\n",
    "# initialize the number of epochs and batch size\n",
    "EPOCHS = 10\n",
    "BS = 256\n",
    "\n",
    "# train the network\n",
    "H = model.fit(train_X, train_label_noisy, batch_size=BS, epochs=EPOCHS,\n",
    "              verbose=1, validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0427e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"def_model_.h5\")\n",
    "\n",
    "def_model = keras.models.load_model('def_model.h5')\n",
    "test_eval = def_model.evaluate(valid_X,valid_label, verbose=0)\n",
    "\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = H.history['accuracy']\n",
    "val_accuracy = H.history['val_accuracy']\n",
    "loss = H.history['loss']\n",
    "val_loss = H.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'c', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'c', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c60116",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = def_model.predict(valid_X)\n",
    "\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
    "valid_labels = np.argmax(np.round(valid_label),axis=1)\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(21)]\n",
    "print(classification_report(valid_labels, predicted_classes, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30251cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6629a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(valid_labels, predicted_classes), target_names = classes)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "bright-brisbane",
    "manufactured-begin",
    "intended-professor",
    "divine-diesel",
    "verified-guarantee"
   ],
   "name": "TFG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
